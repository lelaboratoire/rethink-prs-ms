## Introduction

[@doi:10.1371/journal.pgen.1008060]

As the field of traditional genomics rapidly expands its sequencing technologies and translational abilities, novel applications of genomic data are starting to arise in addressing disease burden. 

Beginning with the completion of the Human Genome Project in 2003, increased interest in
catalouging genomic data spurred the innovation of massively parallel, chip-based genotyping
arrays. 
Leveraging these technologies, early researchers were able to characterize and catalogue gene variants across millions of individuals internationally.
In particular, the advent of projects such as the International HapMap Project [@doi:10.1038/nature02168] and the 1000 Genomes Project sought to document haplotype [@doi:10.1038/nature11632] structure (i.e. gene variants) involved in specific diseases of the human genome.
As such, the gross information of nucleotide polymorphisms within publicly available databases has rapidly increased in the beginning of the 21st century with the rise in omics sequencing capabilities.
This genomic information, coupled with additional high resolution marks for other individual biological variants (e.g. transcripts, epigenetic marks, metabolites) has been touted to further drive precision medicine approaches using genetics.

Complementing the rapid growth in our understanding of gene variants in the human genome was the emergence of using statistical techniques, formalized as genome-wide association studies (GWAS), to identify gene variants associated with common human diseases.
From a population perspective, GWA studies have sought to discern genetic connections to various phenotypes by studying genotypic variation at biallelic markers across the human genome [@doi:10.1371/journal.pcbi.1002822; @doi:10.1038/nrg1521; @doi:10.1038/nrg1522].
Such non-candidate driven GWA studies consider gene variations (i.e. SNPs, deletions, intertions, CNVs) to resulting phenotype values to ultimately report allele frequency differences among a case and control group in the form of an odds ratio.
This technical revolution in the field of genomic medicine fueled our progressing capabilities to map associations of gene variants with disease on an increasingly granular level to single nucleotide polymorphisms (SNPs). 

In tandem with the movement towards precision medicine, the post-GWAS era strives to bring significant population-derived gene variants into individual level metrics actionable in clinical delivery settings.
While GWA studies indeed capture gene variants associated with a phenotype of interest on a population level, translating such results to personalized individual metrics of risk requires additional granularity on aggregating contributions of many gene variants in the form of polygenic risk scores (PRS).
Importantly, PRS have been one such approach developed to explain inherited risk for disease in an individual by representing a weighted sum aggregate of risk alleles based on measured loci effect contributions derived from GWAS studies[@doi:10.1001/jama.2019.3893; ___]. 
(sentence on origin and history & cite it)
In quantifying the effect of particular combinations of genetic SNP variants towards risk prediction, PRS offers a probabilisitic susceptibility value of an individual to disease. Such genetic risk estimation scores are central to clinical decision-making, serving to reinforce individual health management in heritable disease detection and early prevention of various adult-onset conditions. The utility of PRS scores have been demonstrated in previous studies towards disease risk stratification across leading heritable causes of death in the developed world[@doi:10.1038/nature08185; @doi:10.1161/CIRCULATIONAHA.116.024436; @doi:10.1001/jamaoncol.2016.1025; @doi:10.1136/bmj.j5757]

$$PRS=\sum_{i=1}^{n} \beta_i \cdot SNP_i$$

Where $B$ refers to the weighted risk contribution of the loci gene variant and $n$ refers to the total quantity of GWAS 'hits' across the genome.
As one such instance of an equation to calculate overall polygenic risk of an individual, various nuances and limitations arise in this measure of __absolute risk__. 
Historically, PRS models have previously characterized genomic architechture in a dichotimous division of Mendelian monogenic and polygenic inheritance, in which either one or many gene perturbations give rise to disease phenotypes in an individual, respectively[@doi:10.1038/nrg910; @doi:10.1038/s41576-018-0018-x].
Yet while such classification models arose from former sequencing technology and study design, a more realistic genetic archtechture of common adult-onset disease acknowledges dynamic interactions among a continuum of common low-risk to rare high-risk gene variants to cumultatively drive overall risk of an individual[@doi:10.1186/s13059-016-1107-9].
When only considering rare (minor allele frequency, MAF < 0.5%), high-risk gene varian 
ts, such genomic variation only contributes approximately 1-10% towards adult-onset disease incidence[@doi:10.1038/s41576-018-0018-x; @doi: 10.1016/j.ajhg.2015.01.001].
Often, more relevant and complete sources of genetic risk is captured from complex smaller interactions of both common (MAF >5%) and low-frequency (MAF >0.5% and <5%) genetic variants each contributing individual, appreciable effects[@doi:10.1016/j.ajhg.2016.05.013; @doi:10.1038/ng.608]. 
In this context, more robust and efficient methods towards a polygeneic risk calculation are necessary in capturing the overlap between context-dependent effects of both rare and common alleles on human genetic disorder.

Existing standard multivariate categorical data analysis approaches fall short in handling the enormous possible gene interaction combinations with both linear and nonlinear effects. 
With respect to better understanding the epistasis across an individual's genome, various statistical models have been designed with the intent of capturing high dimensional gene-gene (GxG) interactions. 
The Multifactor Dimensionality Reduction (MDR) model is one such model that addresses these challenges and has been extensively applied to detect nonlinear complex GxG interactions associated with individual disease[@doi:10.1186/1756-0381-6-1]. 
By isolating a specific pool of genetic factors from all polymorphism and cross-valiating prediction scores averaged across identified high risk multi-locus genotypes, the original MDR approach is able to categorize multi-loci genotypes into two groups of risk based on some threshold value[@doi:10.1086/321276]. 

MDR has been applied in various studies towards characterizing genomic disease susceptibility with respect to epistasis[Should I cite all from the BioData Mining A-MDR paper?]. 
However, modifications built on top of MDR have been proposed in order to better capture multiple significant epistasis models and potential missed interactions owning to pooling steps. 
Model-Based Multifactor Dimensionality Reduction (MD-MDR) was formulated as a flexible GxG detection framework for dichotomous traits and unrelated individuals[@doi:10.1038/ejhg.2011.17]. 
Rather than a direct comparison against a threshold level in the original MDR method, MD-MDR merges multi-locus genotypes exhibiting significant High or Low risk levels through association testing and adds an additional 'No evidence of risk' categorization. 
Results from MD-MDR analyses on a simulation study reveals that ____[cite the same paper again?]


-In this paper we aim to reformulate the PRS using MD-MDR and observe the separation btwn case and controls
