## Methods

### Multifactor Dimensionality Reduction (MDR) and model-based MDR (MB-MDR)
MDR is a nonparametric method that detects multiple genetic loci associated with a clinical outcome by reducing the dimension of a genotype dataset through pooling multilocus genotypes into high-risk and low-risk groups [@doi:10.1086/321276].
Extended from the original MDR algorithm, MB-MDR was first introduced in 2009, and its current implementation efficiently and effectively detects multiple sets of significant gene-gene interactions in relation to a trait of interest while efficiently controlling type I error rates.

In addition to the test statistic and P values associated with each genotype combination, another important output of MB-MDR is the HLO matrices.
Briefly, in the case of a binary trait, for each genotype combination, an HLO matrix is a 3 x 3 matrix with each cell containing H (high), L (low) or O (no evidence), indicating risk of an individual whose genotype pairs fall into that cell [@doi:10.1186/1471-2105-14-138].
For an example binary outcome problem, a genotype combination $SNP_1$ and $SNP_2$ will have an HLO matrix that looks like
$$ \begin{array}{l|ccc}
& SNP_1 = 0 & SNP_1 = 1 & SNP_1 = 2   \\
\hline
SNP_2 = 0 & O        & O        & O \\
SNP_2 = 1 & O        & H        & L \\
SNP_2 = 2 & O        & L        & H
\end{array}
$$
We discuss in the following subsection how these values were utilized in the formulation of the Multilocus Risk Score (MRS).

[More on the significance of SNP combination vs. significance of H/L/O here...]

### Multilocus Risk Score (MRS)
We apply the MB-MDR software [@doi:10.1186/1471-2105-14-138; @doi:10.1111/j.1469-1809.2010.00604.x] v.4.4.1 to simulated datasets of $n$ individuals, $q$ SNPs to obtain the significance level of each combination of SNPs.
We let $k_d$ denote the number of significant combinations for a specific model dimension $d$ (e.g. $d = 2$ results in pairs of SNPs).
In this study, no significance threshold is imposed at the SNP combination level and, thus, $k_d$ reaches its maximum value of $C^d_p$ ($q$ choose $d$).

For each subject $i$ ($i = 1,2, \dotsm, n$), the $d$-way multilocus risk score is calculated as
$$MRS_d(i) = \sum_{j = 1}^{k_d} \gamma_j \times \textrm{HLO}_j(X_{ij})$$
where $\gamma_j$ is the test statistic of the $j^\textrm{th}$ genotype combination, $X_{ij}$ is the $j^\textrm{th}$ genotype combinations of subject $i$ and $\textrm{HLO}_j$ represents the $j^\textrm{th}$ recoded HLO matrix (1 = High, -1 = Low, 0 = No evidence).
As an example, consider a pair $X_{*j} = (SNP_{j_1}, SNP_{j_2})$ with $\gamma_j=8.3$ and corresponding HLO matrix of all O's except an L in the first cell.
Then, all subjects' current risks would remain the same except the ones with $SNP_{j_1} = SNP_{j_2} = 0$ where their risks are subtracted by 8.3.

In this study, we consider 1-way and 2-way interactions.
We denote by MRS the combined risk score MRS1 + MRS2.
We will compare the performance of the standard PRS method to the combined risk MRS and also its components, MRS1 and MRS2, separately.

### Mutual information and information gain
For a given simulated data set, we apply entropy-based methods to measure how much information about the phenotype is due to either marginal effects or the synergistic effects of the variants after subtracting the marginal effects.
A dataset's amount of main effect $ME$ can be measured as the total of mutual information between each genotype $SNP_j$ and the phenotypic class $y$ based on Shannon's entropy $H$ [@doi:10.1002/j.1538-7305.1948.tb01338.x]:
$$ME = \sum_{j}^k I(SNP_j; y) = \sum_{j}^k H(y) - H(y|SNP_j).$$

We measure the 2-way interaction information (i.e. degree of synergistic effects of genotypes on the phenotype) of each dataset by summing the pairwise information gain between all pairs of genetic attributes.
Specifically, if we let $X_j$ denote the $j^\textrm{th}$ genotype combination $(SNP_{j_1}, SNP_{j_2})$, the total 2-way interaction gain (i.e. synergistic effects $SE$) is calculated as 
$$SE = \sum_{j}^kIG(X_j; y) = \sum_{j}^k \left(I(SNP_{j_1}, SNP_{j_2}; y) - I(SNP_{j_1}; y) - I(SNP_{j_2}; y)\right),$$
where $IG$ measures how much of the phenotypic class $y$ can be explained by the 2-way epistatic interaction within the genotype combination $X_j$.
We refer the reader to Ref. [@doi:10.1007/978-1-4939-2155-3_13] for more details on the calculation of the entropy-based terms.

### Simulated data
The primary objective of this data simulation process was to provide a comprehensive set of reproducible and diverse datasets for the current study.
Containing 1000 individuals and 10 SNPs, each dataset was generated in the following manner.
For an individual, each genotype was randomly assigned with 1/2 probability of being heterozygous (*Aa*, coded as `1`), 1/4 probability of being homozygous major (*AA*, coded as `0`) and 1/4 probability of being homozygous minor (*aa*, coded as `2`).
The binary endpoint for the data was determined using a recently proposed evolutionary-based method for dataset generation called Heuristic Identification of Biological Architectures for simulating Complex Hierarchical Interactions (HIBACHI) [@doi:10.1142/9789813235533_0024].
This method uses Genetic Programming (GP) to build different mathematical and logical models resulting in a binary endpoint, such that the objective function called fitness is maximized. 
The unique feature of HIBACHI is explainability, as each generated model represents a formula for generating the endpoint. 
In this study, to arrive at a diverse collection of datasets, we aim to maximize the difference in predictive performance of all pairs of ten pre-selected classifiers from the extensive library of scikit-learn [@url:https://hal.archives-ouvertes.fr/hal-00650905/] (Table 1).
Therefore, we define the fitness function of HIBACHI as the difference in accuracy between two classifiers. In other words, the first classifier was supposed to perform as well as possible on the data while the second as bad as possible.

Table 1. Selected machine learning methods and their parameters.

| Algorithm      |                             Parameters                                         |
|:--------------:|:------------------------------------------------------------------------------:|
| GaussianNB     |'priors': {None,2}, 'var_smoothing': {1e-9, 1e-7, 1e-5, 1e-3, 1e-1, 1e+1}       |
| BernoulliNB    |'alpha': {1e-3, 1e-2, 1e-1, 1., 10., 100.},'fit_prior': {True, False}           |
| DecisionTree   |'criterion': {"gini", "entropy"}, 'max_depth': [1, 11], 'min_samples_split': [2, 21], 'min_samples_leaf': [1, 21]|
|ExtraTrees      |'n_estimators': {50,100}, 'criterion': {"gini", "entropy"},'max_features': [0.1, 1], 'min_samples_split': range(2, 21,2),'min_samples_leaf': range(1, 21,2), 'bootstrap': {True, False}|
|RandomForest    |'n_estimators': {50,100}, 'criterion': {"gini", "entropy"},'max_features': [0.1, 1], 'min_samples_split': range(2, 21,4), 'min_samples_leaf':  range(1, 21,5), 'bootstrap': {True, False}                 |
|GradientBoosting|  'n_estimators': {50,100},'learning_rate': {1e-3, 1e-2, 1e-1, 0.5, 1}, 'max_depth': {2,4,8}, 'min_samples_split': [2, 21], 'min_samples_leaf': [1, 21], 'subsample': [0.1, 1], 'max_features': [0.1, 1]|
|KNeighbors      |'n_neighbors': [1, 100], 'weights': {"uniform", "distance"} , 'p': {1, 2}   |
|LogisticRegression| 'C': {1e-3, 1e-2, 1e-1, 1., 10.}, 'solver' : {'newton-cg', 'lbfgs', 'liblinear', 'sag'}|
|XGBoost     | 'n_estimators'=100, 'max_depth': [2, 10], 'learning_rate': {1e-3, 1e-2, 1e-1, 0.5, 1.}, 'subsample': [0.05, 1], 'min_child_weight': [1, 20],
|MLPClassifier |: 'hidden_layer_sizes': {(10),(11),(12),(13),(14),(15),(10,5)},  'activation': {'logistic','tanh','relu'}, 'solver': ['lbfgs'], 'learning_rate': {'constant','invscaling'}, 'max_iter'=1000, 'alpha':np.logspace(-4,1,4)|

HIBACHI was run for 50 iterations with population of 500 individuals representing pairs of classifiers.
At each iteration, five randomly chosen settings for each of the classifiers (Table 1) were chosen among all potential options and served as hyperparameters for that method.
Each of the settings was analyzed using 5-fold cross-validation and the best set of hyperparameters for each classifier was considered for comparison. 
The best settings out of 5 for each classifiers were compared and the settings that maximized the difference in the fitness were promoted.
Each experiment in which one machine learning method was expected to outperform the other was repeated five times.
The results of each pair of classifiers were later averaged.

For each simulated dataset, after randomly splitting the entire data in two smaller sets (80% training and 20% holdout), we built the MRS model on training data to obtain the $\gamma$ coefficients and the HLO matrix, and then we calculated risk score for each individual in the holdout set.
We assess the performance of the MRS by comparing the area under the Receiving Operator Characteristic curve (auROC) with that of the standard PRS method on the holdout set.

### Manuscript drafting
This manuscript is collaboratively written using the Manubot software which supports open paper writing via GitHub with Markdown [@doi:10.1371/journal.pcbi.1007128].
Manubot uses continuous integration to monitor changes and automatically update the manuscript.
As a result, the latest version of this manuscript is always available at [https://lelaboratoire.github.io/rethink-prs-ms/](https://lelaboratoire.github.io/rethink-prs-ms/).


### Availability
Detailed simulation and analysis code needed to reproduce the results in this study is available at [https://github.com/lelaboratoire/rethink-prs/](https://github.com/lelaboratoire/rethink-prs/).

